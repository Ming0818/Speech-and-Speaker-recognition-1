%% DT2119 - Speech and speaker recognition - Lab 1 - Feature extraction

%%
% Mel Frequency Cepstral Coefficients (MFCCs) are coefficients used in
% Speech recognition based on human auditive perception. These coefficients
% come from the need, in the field of aoutonomous audio recognition, to
% extract the main features of an audio signal while discarding all the
% irrelevant features that will make the recognition harder to achieve
% (background noise, emotion ...)
%
% The sounds generated by a human depend on the shape of the vocal tract,
% position of the tongue, teeth, lips etc. Then, if we can determine this
% shape accurately, the phoneme that was produced will be easy to identify.
% The main objetive of the MFCC it to accurately represent the envelope of
% the short time power spectrum in order to stablish the shape of the vocal
% tract. Consisting then of one of the most important features in Speech
% recognition

%%
% First we need to prepare the workspace and load the data set
clear all;
close all; 
load('tidigits.mat')
load('example.mat')


%% 1.1 Enframe the audio signal
%
% The purpose of this first step is to cut the original sample in many
% smaller ones. In this case, we want windowframes of 20 ms with a shift
% between windows of 10 ms. As the shift is smaller than the window, the
% computed frames will have shared parts between each other
%
% _*Compute the number of samples per frame and shift*_
% 
% The sampling rate is S = 20 kHz. Then the period is $T = 1/S$. 
% We have that: 
%
% Length of the window: $0.02T = 400$ samples
% Length of the shift: $0.01T = 200$ samples


winlen = 400;
winshift = 200; 

%%
% Now is time to check the performance of the written function. To do so,
% the function is evaluated with the example's structure data set, and compared to the
% frames given in the example's structure frames. The output generated must
% be identical to the frames stored in the data structure in example.

samples = example{1,1}.samples; 
test = example{1,1}.frames;
frames = enframe(samples,winlen,winshift);
% As the image have to be plotted in with the same orientation as in the
% test data then
frames = frames(:,1:400)'; 
%% 
% The comparison is shown in the folowwing figure. 
subplot(2,1,1)
imagesc(frames)
colormap jet
title(' Enframe function output')
subplot(2,1,2)
imagesc(test')
colormap jet
title(' Test frames set')

%%
% To check the performance numerically, we will substract the test data
% from the output and get the total differences between both of them

subs = test' - frames;
Enframe_error = sum(sum(subs))
%% 1.2 Pre-emphasys
%
% The main objetive of this function is to compesate the 6dB/octave that
% are dropped due to the radiation at the lips. This funcion is: 
%
% $y[n] = x[n] - ax[n-1]$
%
% Being the coefficientes  $A = 1$ and $B = [1 -a]$.
%
% The purpose of substracting the main part of the previous input is
% because the important features are in the higher frequencias, remaining
% the lower frequencies almost unchenged. Therefor, doing the substraction
% we discard the similar parts of the signal analyzing only the higher
% frequencies, where the important features are. 
%
% We have now to check the performance of the written function. To do so,
% we have to compare the output of this function with the test data. 

a = 0.97;
preemph = preemp(frames,a);
test_preem = example{1,1}.preemph;

%% 
% The comparison is shown in the folowwing figure. 
figure;
subplot(2,1,1)
imagesc(preemph)
colormap jet
title(' Preemp function output')
subplot(2,1,2)
imagesc(test_preem')
colormap jet
title(' Test preemphashis set')

%%
% To check the performance numerically, we will substract the test data
% from the output and get the total differences between both of them

subs = test_preem' - preemph;
Preemphasis_error = sum(sum(subs))