
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>DT2119 - Speech and speaker recognition - Lab 1 - Feature extraction</title><meta name="generator" content="MATLAB 9.1"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-04-03"><meta name="DC.source" content="Feature_Extraction.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>DT2119 - Speech and speaker recognition - Lab 1 - Feature extraction</h1><!--introduction--><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#3">1.1 Enframe the audio signal</a></li><li><a href="#7">1.2 Pre-emphasys</a></li><li><a href="#10">1.3 Hamming window</a></li><li><a href="#15">1.4 Fast Fourier Transform</a></li><li><a href="#19">1.5 Mel filterbank log spectrum</a></li></ul></div><p>Mel Frequency Cepstral Coefficients (MFCCs) are coefficients used in Speech recognition based on human auditive perception. These coefficients come from the need, in the field of aoutonomous audio recognition, to extract the main features of an audio signal while discarding all the irrelevant features that will make the recognition harder to achieve (background noise, emotion ...)</p><p>The sounds generated by a human depend on the shape of the vocal tract, position of the tongue, teeth, lips etc. Then, if we can determine this shape accurately, the phoneme that was produced will be easy to identify. The main objetive of the MFCC it to accurately represent the envelope of the short time power spectrum in order to stablish the shape of the vocal tract. Consisting then of one of the most important features in Speech recognition</p><p>First we need to prepare the workspace and load the data set</p><pre class="codeinput">clear <span class="string">all</span>;
close <span class="string">all</span>;
load(<span class="string">'tidigits.mat'</span>)
load(<span class="string">'example.mat'</span>)
</pre><h2 id="3">1.1 Enframe the audio signal</h2><p>The purpose of this first step is to cut the original sample in many smaller ones. In this case, we want windowframes of 20 ms with a shift between windows of 10 ms. As the shift is smaller than the window, the computed frames will have shared parts between each other</p><p><i><b>Compute the number of samples per frame and shift</b></i></p><p>The sampling rate is S = 20 kHz. Then the period is <img src="Feature_Extraction_eq08067570237043316922.png" alt="$T = 1/S$">. We have that:</p><p>Length of the window: <img src="Feature_Extraction_eq09482477169178125687.png" alt="$0.02T = 400$"> samples Length of the shift: <img src="Feature_Extraction_eq11115082160516153914.png" alt="$0.01T = 200$"> samples</p><pre class="codeinput">winlen = 400;
winshift = 200;
</pre><p>Now is time to check the performance of the written function. To do so, the function is evaluated with the example's structure data set, and compared to the frames given in the example's structure frames. The output generated must be identical to the frames stored in the data structure in example.</p><pre class="codeinput">samples = example{1,1}.samples;
test = example{1,1}.frames';
frames = enframe(samples,winlen,winshift);
<span class="comment">% As the image have to be plotted in with the same orientation as in the</span>
<span class="comment">% test data then</span>
frames = frames(:,1:400)';
</pre><p>The comparison is shown in the folowwing figure.</p><pre class="codeinput">subplot(2,1,1)
imagesc(frames)
colormap <span class="string">jet</span>
title(<span class="string">' Enframe function output'</span>)
subplot(2,1,2)
imagesc(test)
colormap <span class="string">jet</span>
title(<span class="string">' Test frames set'</span>)
</pre><img vspace="5" hspace="5" src="Feature_Extraction_01.png" alt=""> <p>To check the performance numerically, we will substract the test data from the output and get the total differences between both of them</p><pre class="codeinput">subs = test - frames;
Enframe_error = sum(sum(subs))
</pre><pre class="codeoutput">
Enframe_error =

     0

</pre><h2 id="7">1.2 Pre-emphasys</h2><p>The main objetive of this function is to compesate the 6dB/octave that are dropped due to the radiation at the lips. This funcion is:</p><p><img src="Feature_Extraction_eq01683044689347843080.png" alt="$y[n] = x[n] - ax[n-1]$"></p><p>Being the coefficientes  <img src="Feature_Extraction_eq12755552376203169728.png" alt="$A = 1$"> and <img src="Feature_Extraction_eq18042384864992526626.png" alt="$B = [1 -a]$">.</p><p>The purpose of substracting the main part of the previous input is because the important features are in the higher frequencias, remaining the lower frequencies almost unchenged. Therefor, doing the substraction we discard the similar parts of the signal analyzing only the higher frequencies, where the important features are.</p><p>We have now to check the performance of the written function. To do so, we have to compare the output of this function with the test data.</p><pre class="codeinput">a = 0.97;
preemph = preemp(frames,a);
test_preem = example{1,1}.preemph';
</pre><p>The comparison is shown in the folowwing figure.</p><pre class="codeinput">figure;
subplot(2,1,1)
imagesc(preemph)
colormap <span class="string">jet</span>
title(<span class="string">' Preemp function output'</span>)
subplot(2,1,2)
imagesc(test_preem)
colormap <span class="string">jet</span>
title(<span class="string">' Test preemphashis set'</span>)
</pre><img vspace="5" hspace="5" src="Feature_Extraction_02.png" alt=""> <p>To check the performance numerically, we will substract the test data from the output and get the total differences between both of them</p><pre class="codeinput">subs = test_preem - preemph;
Preemphasis_error = sum(sum(subs))
</pre><pre class="codeoutput">
Preemphasis_error =

     0

</pre><h2 id="10">1.3 Hamming window</h2><p>The use of the Hamming window is justified as it emphasizes the center of the window, improving this way the values of the Fourier Transfer Function. The sidelobes are reduced, being the center lobe much important than these side lobes.</p><p>The Hamming window is used in order to reduce the discontinuities in the edges of the frames, focusing in the main(centered) frequencies.</p><p>The function windowing that applies the hamming window is implemented and used on the pre emphasized frames.</p><pre class="codeinput">[windowed_frames, window] = windowing(preemph);
test_windowed = example{1,1}.windowed';
</pre><p>The shape of the Hamming window used is figure; <a href="<FIGURE_WINDOW.BMP">&lt;FIGURE_WINDOW.BMP</a>&gt;</p><p>We have now to check the performance of the written function. To do so, we have to compare the output of this function with the test data.</p><pre class="codeinput">figure;
subplot(2,1,1)
imagesc(windowed_frames)
colormap <span class="string">jet</span>
title(<span class="string">' Windowing function output'</span>)
subplot(2,1,2)
imagesc(test_windowed)
colormap <span class="string">jet</span>
title(<span class="string">' Test windowing set'</span>)
</pre><img vspace="5" hspace="5" src="Feature_Extraction_03.png" alt=""> <p>To check the performance numerically, we will substract the test data from the output and get the total differences between both of them</p><pre class="codeinput">subs = test_windowed - windowed_frames;
window_error = sum(sum(subs))
</pre><pre class="codeoutput">
window_error =

    -7.791701311932187e-13

</pre><p>We can observe that the error is not exactly cero but is sufficiently small enough. The insignificant difference is probably due to the use of Matlab instead of Python.</p><h2 id="15">1.4 Fast Fourier Transform</h2><p>The powerSpectrum function is developed in this section. This function performs the Fast fourier Transform to the windowed frames and a then applies a squared power to the modulus.</p><p>As now er are in the frequency domain, it is interesting what the max frequency will be:</p><p><img src="Feature_Extraction_eq17991088040002015184.png" alt="$$f_{max}=\frac{f_{samp}}{2}=\frac{20000}{2} = 10 kHz$$"></p><pre class="codeinput">nfft = 512;
FFT_frame = powerSpectrum(windowed_frames,nfft);
test_FFT = example{1,1}.spec';
</pre><p>We have now to check the performance of the written function. To do so, we have to compare the output of this function with the test data.</p><pre class="codeinput">figure;
subplot(2,1,1)
imagesc(FFT_frame)
title(<span class="string">' Power Spectrum output'</span>)
subplot(2,1,2)
imagesc(test_FFT)
title(<span class="string">' Test Power Spectrum set'</span>)
</pre><img vspace="5" hspace="5" src="Feature_Extraction_04.png" alt=""> <p>To check the performance numerically, we will substract the test data from the output and get the total differences between both of them</p><pre class="codeinput">subs = test_FFT - FFT_frame;
FFT_error = sum(sum(subs))
figure
</pre><pre class="codeoutput">
FFT_error =

    -2.497053070175601e-07

</pre><img vspace="5" hspace="5" src="Feature_Extraction_05.png" alt=""> <p>As expected, the error is not 0 as we get the errors from the previous step, but squared. Still the error is too small to be considered.</p><h2 id="19">1.5 Mel filterbank log spectrum</h2><p>A filter bank is a set a filters. In the case of the Mel fiterbank, these filters are triangles, in which the first filter only keeps low frequencies while the next filters slowly shift to higher frequencies and the amplitude of the triangles decrease, and they get wider.</p><p>This decreased amplitude try to represent the human ear system, as the higher the frequencies, the more difficult discern differences. This is why the triangles get wider: we need a bigger filter as the resolution is less precise.</p><p>The sum of the energy in every filter is computed. We need to take the log of this energy due to the log property of sound: to double the sound we need 8 times more energy.</p><pre class="codeinput">sampling_freq = 20000;
[melSpec_frames, filterBank] = logMelSpectrum(FFT_frame,sampling_freq);
test_melSpec = example{1,1}.mspec';
</pre><pre class="codeoutput">
linsc =

  66.666666666666671

</pre><p>Data need to be fliped to get the same output as in Python</p><pre class="codeinput">test_melSpec = flipdim(test_melSpec ,1);           <span class="comment">%# vertical flip</span>
melSpec_frames = flipdim(melSpec_frames ,1);           <span class="comment">%# vertical flip</span>
</pre><p>The Mel filter bank computed is the one that follows</p><pre class="codeinput">figure(<span class="string">'Name'</span>,<span class="string">'Mel Frequency Filter Bank'</span>)
plot(filterBank')
axis([0, 178,  0, max(max(filterBank))])
title(<span class="string">'Mel-filterbank'</span>)
</pre><img vspace="5" hspace="5" src="Feature_Extraction_06.png" alt=""> <p>We have now to check the performance of the written function. To do so, we have to compare the output of this function with the test data.</p><pre class="codeinput">figure;
subplot(2,1,1)
imagesc(melSpec_frames)
title(<span class="string">' Power Spectrum output'</span>)
colormap <span class="string">jet</span>
subplot(2,1,2)
imagesc(test_melSpec)
title(<span class="string">' Test Power Spectrum set'</span>)
colormap <span class="string">jet</span>
</pre><img vspace="5" hspace="5" src="Feature_Extraction_07.png" alt=""> <p>To check the performance numerically, we will substract the test data from the output and get the total differences between both of them</p><pre class="codeinput">subs = test_melSpec - melSpec_frames;
melSpec_error = sum(sum(subs))
</pre><pre class="codeoutput">
melSpec_error =

     3.582160609805207e-14

</pre><p>As expected, the error is not 0 as we get the errors from the previous step, but squared. Still the error is too small to be considered.</p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2016b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% DT2119 - Speech and speaker recognition - Lab 1 - Feature extraction

%%
% Mel Frequency Cepstral Coefficients (MFCCs) are coefficients used in
% Speech recognition based on human auditive perception. These coefficients
% come from the need, in the field of aoutonomous audio recognition, to
% extract the main features of an audio signal while discarding all the
% irrelevant features that will make the recognition harder to achieve
% (background noise, emotion ...)
%
% The sounds generated by a human depend on the shape of the vocal tract,
% position of the tongue, teeth, lips etc. Then, if we can determine this
% shape accurately, the phoneme that was produced will be easy to identify.
% The main objetive of the MFCC it to accurately represent the envelope of
% the short time power spectrum in order to stablish the shape of the vocal
% tract. Consisting then of one of the most important features in Speech
% recognition

%%
% First we need to prepare the workspace and load the data set
clear all;
close all; 
load('tidigits.mat')
load('example.mat')


%% 1.1 Enframe the audio signal
%
% The purpose of this first step is to cut the original sample in many
% smaller ones. In this case, we want windowframes of 20 ms with a shift
% between windows of 10 ms. As the shift is smaller than the window, the
% computed frames will have shared parts between each other
%
% _*Compute the number of samples per frame and shift*_
% 
% The sampling rate is S = 20 kHz. Then the period is $T = 1/S$. 
% We have that: 
%
% Length of the window: $0.02T = 400$ samples
% Length of the shift: $0.01T = 200$ samples


winlen = 400;
winshift = 200; 

%%
% Now is time to check the performance of the written function. To do so,
% the function is evaluated with the example's structure data set, and compared to the
% frames given in the example's structure frames. The output generated must
% be identical to the frames stored in the data structure in example.

samples = example{1,1}.samples; 
test = example{1,1}.frames';
frames = enframe(samples,winlen,winshift);
% As the image have to be plotted in with the same orientation as in the
% test data then
frames = frames(:,1:400)'; 
%% 
% The comparison is shown in the folowwing figure. 
subplot(2,1,1)
imagesc(frames)
colormap jet
title(' Enframe function output')
subplot(2,1,2)
imagesc(test)
colormap jet
title(' Test frames set')

%%
% To check the performance numerically, we will substract the test data
% from the output and get the total differences between both of them

subs = test - frames;
Enframe_error = sum(sum(subs))
%% 1.2 Pre-emphasys
%
% The main objetive of this function is to compesate the 6dB/octave that
% are dropped due to the radiation at the lips. This funcion is: 
%
% $y[n] = x[n] - ax[n-1]$
%
% Being the coefficientes  $A = 1$ and $B = [1 -a]$.
%
% The purpose of substracting the main part of the previous input is
% because the important features are in the higher frequencias, remaining
% the lower frequencies almost unchenged. Therefor, doing the substraction
% we discard the similar parts of the signal analyzing only the higher
% frequencies, where the important features are. 
%
% We have now to check the performance of the written function. To do so,
% we have to compare the output of this function with the test data. 

a = 0.97;
preemph = preemp(frames,a);
test_preem = example{1,1}.preemph';

%% 
% The comparison is shown in the folowwing figure. 
figure;
subplot(2,1,1)
imagesc(preemph)
colormap jet
title(' Preemp function output')
subplot(2,1,2)
imagesc(test_preem)
colormap jet
title(' Test preemphashis set')

%%
% To check the performance numerically, we will substract the test data
% from the output and get the total differences between both of them

subs = test_preem - preemph;
Preemphasis_error = sum(sum(subs))

%% 1.3 Hamming window
%
% The use of the Hamming window is justified as it emphasizes the center of
% the window, improving this way the values of the Fourier Transfer
% Function. The sidelobes are reduced, being the center lobe much important
% than these side lobes. 
%
% The Hamming window is used in order to reduce the discontinuities in the
% edges of the frames, focusing in the main(centered) frequencies. 
%
% The function windowing that applies the hamming window is implemented and
% used on the pre emphasized frames. 

[windowed_frames, window] = windowing(preemph);
test_windowed = example{1,1}.windowed';
%%
% The shape of the Hamming window used is
% figure;
% <<FIGURE_WINDOW.BMP>>

%%
% We have now to check the performance of the written function. To do so,
% we have to compare the output of this function with the test data.
figure;
subplot(2,1,1)
imagesc(windowed_frames)
colormap jet
title(' Windowing function output')
subplot(2,1,2)
imagesc(test_windowed)
colormap jet
title(' Test windowing set')

%%
% To check the performance numerically, we will substract the test data
% from the output and get the total differences between both of them

subs = test_windowed - windowed_frames;
window_error = sum(sum(subs))

%%
% We can observe that the error is not exactly cero but is sufficiently
% small enough. The insignificant difference is probably due to the use of
% Matlab instead of Python. 

%% 1.4 Fast Fourier Transform
%
% The powerSpectrum function is developed in this section. This function
% performs the Fast fourier Transform to the windowed frames and a then
% applies a squared power to the modulus. 
%
% As now er are in the frequency domain, it is interesting what the max
% frequency will be: 
%
% $$f_{max}=\frac{f_{samp}}{2}=\frac{20000}{2} = 10 kHz$$
nfft = 512;
FFT_frame = powerSpectrum(windowed_frames,nfft);
test_FFT = example{1,1}.spec';

%%
% We have now to check the performance of the written function. To do so,
% we have to compare the output of this function with the test data.
figure;
subplot(2,1,1)
imagesc(FFT_frame)
title(' Power Spectrum output')
subplot(2,1,2)
imagesc(test_FFT)
title(' Test Power Spectrum set')

%%
% To check the performance numerically, we will substract the test data
% from the output and get the total differences between both of them

subs = test_FFT - FFT_frame;
FFT_error = sum(sum(subs))
figure
%%
% As expected, the error is not 0 as we get the errors from the previous
% step, but squared. Still the error is too small to be considered.

%% 1.5 Mel filterbank log spectrum
%
% A filter bank is a set a filters. In the case of the Mel fiterbank, these
% filters are triangles, in which the first filter only keeps low
% frequencies while the next filters slowly shift to higher frequencies and
% the amplitude of the triangles decrease, and they get wider. 
%
% This decreased amplitude try to represent the human ear system, as the
% higher the frequencies, the more difficult discern differences. This is
% why the triangles get wider: we need a bigger filter as the resolution is
% less precise.
%
% The sum of the energy in every filter is computed. We need to take the
% log of this energy due to the log property of sound: to double the sound
% we need 8 times more energy. 

sampling_freq = 20000;
[melSpec_frames, filterBank] = logMelSpectrum(FFT_frame,sampling_freq);
test_melSpec = example{1,1}.mspec';

%%
% Data need to be fliped to get the same output as in Python
test_melSpec = flipdim(test_melSpec ,1);           %# vertical flip
melSpec_frames = flipdim(melSpec_frames ,1);           %# vertical flip
%%
% The Mel filter bank computed is the one that follows
figure('Name','Mel Frequency Filter Bank')
plot(filterBank')
axis([0, 178,  0, max(max(filterBank))])
title('Mel-filterbank')
%%
% We have now to check the performance of the written function. To do so,
% we have to compare the output of this function with the test data.
figure;
subplot(2,1,1)
imagesc(melSpec_frames)
title(' Power Spectrum output')
colormap jet
subplot(2,1,2)
imagesc(test_melSpec)
title(' Test Power Spectrum set')
colormap jet

%%
% To check the performance numerically, we will substract the test data
% from the output and get the total differences between both of them
subs = test_melSpec - melSpec_frames;
melSpec_error = sum(sum(subs))

%%
% As expected, the error is not 0 as we get the errors from the previous
% step, but squared. Still the error is too small to be considered.


##### SOURCE END #####
--></body></html>